{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YZut5l11v4ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5AqLLULvhdZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "import logging\n",
        "import joblib\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import optuna\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, roc_auc_score, confusion_matrix,\n",
        "    precision_recall_curve, roc_curve, auc, make_scorer,\n",
        "    precision_score, recall_score, balanced_accuracy_score,\n",
        "    log_loss, matthews_corrcoef, classification_report\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ========= CONFIG ===========================================================\n",
        "RAW_CSV         = '/content/drive/MyDrive/Colab Notebooks/패턴인식/data/train.csv'\n",
        "BASE_DIR        = '/content/drive/MyDrive/Colab Notebooks/패턴인식'\n",
        "USE_GPU         = False             # Colab GPU 사용 시 True\n",
        "GPU_DEVICES     = \"0\"\n",
        "GPU_RAM_PART    = 0.50              # GPU 메모리 사용 비율 (CatBoost 전용)\n",
        "GLOBAL_SEED     = 42\n",
        "\n",
        "N_TRIALS_OPTUNA = 30                # Optuna 탐색 횟수\n",
        "SEARCH_N_JOBS   = 1                 # Optuna 병렬 worker 수\n",
        "TRAIN_ITER      = 1                 # trial-/final-model 공통 반복 횟수\n",
        "EARLY_STOP      = 50\n",
        "N_DPND_FEATS    = 3                 # SHAP dependence plot용 상위 피처 개수\n",
        "# ============================================================================\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if USE_GPU:\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_DEVICES\n",
        "else:\n",
        "    os.environ.pop(\"CUDA_VISIBLE_DEVICES\", None)\n",
        "\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "\n",
        "# -------- 결과 디렉토리 생성 ------------------------------------------------\n",
        "log_root   = os.path.join(BASE_DIR, 'log')\n",
        "timestamp  = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "RES_DIR    = os.path.join(log_root, f'optuna_run_{timestamp}')\n",
        "PLOT_DIR   = os.path.join(RES_DIR, 'img')\n",
        "\n",
        "os.makedirs(RES_DIR, exist_ok=True)\n",
        "os.makedirs(PLOT_DIR, exist_ok=True)\n",
        "\n",
        "MODEL_CBM  = os.path.join(RES_DIR, 'final_model.cbm')\n",
        "FI_CSV     = os.path.join(RES_DIR, 'feature_importances.csv')\n",
        "PI_CSV     = os.path.join(RES_DIR, 'permutation_importances.csv')\n",
        "LOG_TXT    = os.path.join(RES_DIR, 'log.txt')\n",
        "\n",
        "logging.root.handlers.clear()\n",
        "\n",
        "logging.basicConfig(\n",
        "    level    = logging.INFO,\n",
        "    format   = \"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    handlers = [logging.FileHandler(LOG_TXT), logging.StreamHandler()]\n",
        ")\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "logger.info(\"===== 스크립트 시작 =====\")\n",
        "logger.info(\"CUDA_VISIBLE_DEVICES=%s\", os.getenv(\"CUDA_VISIBLE_DEVICES\", \"CPU\"))\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 1. Data Load & Derived Feature 생성\n",
        "# ============================================================================\n",
        "logger.info(\"1) Loading data from: %s\", RAW_CSV)\n",
        "df = pd.read_csv(RAW_CSV)\n",
        "# 'id', 'shares' 제거, 'y'를 타겟으로 사용\n",
        "X_full = df.drop(columns=['id', 'shares', 'y'], errors='ignore').copy()\n",
        "y_full = df['y'].copy()\n",
        "\n",
        "EPS = 1e-6\n",
        "def add_derived(df_):\n",
        "    df_ = df_.copy()\n",
        "    if {'n_tokens_content','num_imgs'}.issubset(df_.columns):\n",
        "        df_['feat_content_to_img_ratio'] = df_['n_tokens_content'] / (df_['num_imgs'] + EPS)\n",
        "    if {'global_subjectivity','global_sentiment_polarity'}.issubset(df_.columns):\n",
        "        df_['feat_global_sentiment_strength'] = df_['global_subjectivity'] * df_['global_sentiment_polarity']\n",
        "    if {'n_tokens_content','num_hrefs'}.issubset(df_.columns):\n",
        "        df_['feat_content_to_href_ratio'] = df_['n_tokens_content'] / (df_['num_hrefs'] + EPS)\n",
        "    return df_\n",
        "\n",
        "X_full = add_derived(X_full)\n",
        "\n",
        "# Train/Validation Hold-out 분할\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_full, y_full, test_size=0.2, stratify=y_full, random_state=GLOBAL_SEED\n",
        ")\n",
        "logger.info(\"   - Train shape: %s, Validation shape: %s\", X_tr.shape, X_val.shape)\n",
        "\n",
        "# 결측치 처리: 숫자형 → 중앙값, 범주형 → 'missing'\n",
        "num_cols = X_tr.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = [c for c in ['data_channel', 'weekday'] if c in X_tr.columns]\n",
        "\n",
        "meds = X_tr[num_cols].median()\n",
        "X_tr[num_cols]  = X_tr[num_cols].fillna(meds)\n",
        "X_val[num_cols] = X_val[num_cols].fillna(meds)\n",
        "\n",
        "if cat_cols:\n",
        "    for c in cat_cols:\n",
        "        X_tr[c].fillna('missing', inplace=True)\n",
        "        X_val[c].fillna('missing', inplace=True)\n",
        "else:\n",
        "    logger.info(\"No categorical columns identified for imputation.\")\n",
        "\n",
        "# 클래스 불균형 가중치 계산\n",
        "pos, neg = (y_tr == 1).sum(), (y_tr == 0).sum()\n",
        "scale_pos_weight = neg / pos if pos else 1.0\n",
        "logger.info(\"scale_pos_weight=%.3f  (neg=%d, pos=%d)\", scale_pos_weight, neg, pos)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 2. Custom CompositeMetric for CatBoost\n",
        "# ============================================================================\n",
        "class CompositeMetric:\n",
        "    def get_final_error(self, error, weight):\n",
        "        return error / (weight + 1e-10)\n",
        "    def is_max_optimal(self):\n",
        "        return True\n",
        "    def evaluate(self, approxes, target, weight):\n",
        "        prob = 1.0 / (1.0 + np.exp(-approxes[0]))\n",
        "        pred = (prob >= 0.5).astype(int)\n",
        "        m = (accuracy_score(target, pred)\n",
        "             + f1_score(target, pred)\n",
        "             + roc_auc_score(target, prob)) / 3\n",
        "        return m, 1.0\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 3. Optuna Objective 정의\n",
        "# ============================================================================\n",
        "def cb_params(trial):\n",
        "    return {\n",
        "        'iterations'           : TRAIN_ITER,\n",
        "        'learning_rate'        : trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
        "        'depth'                : trial.suggest_int('depth', 4, 10),\n",
        "        'l2_leaf_reg'          : trial.suggest_float('l2_leaf_reg', 1.0, 12.0, log=True),\n",
        "        'border_count'         : trial.suggest_int('border_count', 32, 254),\n",
        "        'bagging_temperature'  : trial.suggest_float('bagging_temperature', 0.0, 2.0),\n",
        "        'random_strength'      : trial.suggest_float('random_strength', 0.1, 5.0, log=True),\n",
        "        'colsample_bylevel'    : trial.suggest_float('colsample_bylevel', 0.6, 1.0),\n",
        "        'task_type'            : 'GPU' if USE_GPU else 'CPU',\n",
        "        'devices'              : GPU_DEVICES if USE_GPU else None,\n",
        "        'gpu_ram_part'         : GPU_RAM_PART if USE_GPU else None,\n",
        "        'scale_pos_weight'     : scale_pos_weight,\n",
        "        'eval_metric'          : CompositeMetric(),\n",
        "        'early_stopping_rounds': EARLY_STOP,\n",
        "        'use_best_model'       : True,\n",
        "        'verbose'              : False,\n",
        "        'random_state'         : GLOBAL_SEED,\n",
        "    }\n",
        "\n",
        "def objective(trial):\n",
        "    params = cb_params(trial)\n",
        "    model = CatBoostClassifier(**params)\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        cat_features=cat_cols or None,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=False\n",
        "    )\n",
        "    # 최적 CompositeMetric을 반환\n",
        "    return model.get_best_score()['validation']['CompositeMetric']\n",
        "\n",
        "logger.info(\"Optuna search (%d trials) 시작\", N_TRIALS_OPTUNA)\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=N_TRIALS_OPTUNA, n_jobs=SEARCH_N_JOBS, show_progress_bar=True)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_score  = study.best_value\n",
        "logger.info(\"Optuna best params: %s  |  best Composite=%.4f\", best_params, best_score)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 4. Final Model 학습\n",
        "# ============================================================================\n",
        "# Optuna에서 찾은 best_params로 학습\n",
        "final_params = cb_params(optuna.trial.FixedTrial(best_params))\n",
        "# 최종 학습 시 iterations=TRAIN_ITER, verbose= 3 으로 설정\n",
        "final_params.update({'iterations': TRAIN_ITER, 'verbose': 3})\n",
        "\n",
        "final_model = CatBoostClassifier(**final_params)\n",
        "final_model.fit(\n",
        "    X_tr, y_tr,\n",
        "    cat_features=cat_cols or None,\n",
        "    eval_set=[(X_val, y_val)]\n",
        ")\n",
        "\n",
        "best_iter = final_model.get_best_iteration()\n",
        "logger.info(\"Best iteration via early-stopping: %d\", best_iter)\n",
        "final_model.save_model(MODEL_CBM)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 5. Learning-Curve Plot (Logloss & Composite Proxy)\n",
        "# ============================================================================\n",
        "def save_learning_curve(metric_key, fname):\n",
        "    ev  = final_model.get_evals_result()\n",
        "    tr  = ev['learn'][metric_key]\n",
        "    val = ev['validation'][metric_key]\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(tr,  label=f'train {metric_key}')\n",
        "    plt.plot(val, label=f'valid {metric_key}')\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel(metric_key)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(PLOT_DIR, fname), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "save_learning_curve('Logloss', 'learning_curve_logloss.jpg')\n",
        "save_learning_curve('CompositeMetric', 'learning_curve_composite.jpg')\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 6. Hold-Out Validation 성능 평가\n",
        "# ============================================================================\n",
        "logger.info(\"6) Hold-out Validation Performance 계산 중...\")\n",
        "y_prob = final_model.predict_proba(X_val)[:, 1]\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "# 주요 지표 계산\n",
        "acc_val            = accuracy_score(y_val, y_pred)\n",
        "precision_val      = precision_score(y_val, y_pred)\n",
        "recall_val         = recall_score(y_val, y_pred)\n",
        "f1_val             = f1_score(y_val, y_pred)\n",
        "auc_val            = roc_auc_score(y_val, y_prob)\n",
        "mcc_val            = matthews_corrcoef(y_val, y_pred)\n",
        "balanced_acc_val   = balanced_accuracy_score(y_val, y_pred)\n",
        "logloss_val        = log_loss(y_val, y_prob)\n",
        "comp_val           = (acc_val + f1_val + auc_val) / 3\n",
        "\n",
        "# Top-K Precision 계산 (상위 10% positive)\n",
        "k_val              = max(1, int(0.1 * sum(y_val)))\n",
        "top_k_indices_val  = np.argsort(y_prob)[-k_val:]\n",
        "top_k_precision_val = sum(y_val.iloc[top_k_indices_val]) / k_val\n",
        "\n",
        "logger.info(\"Hold-out Acc=%.4f  Precision=%.4f  Recall=%.4f  F1=%.4f  AUC=%.4f\",\n",
        "            acc_val, precision_val, recall_val, f1_val, auc_val)\n",
        "logger.info(\"       MCC=%.4f  BalAcc=%.4f  LogLoss=%.4f  Composite=%.4f  Top-%d Precision=%.4f\",\n",
        "            mcc_val, balanced_acc_val, logloss_val, comp_val, k_val, top_k_precision_val)\n",
        "\n",
        "# Confusion Matrix (Hold-out)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Not Popular','Popular'],\n",
        "            yticklabels=['Not Popular','Popular'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (Hold-out)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOT_DIR, 'confusion_matrix_holdout.jpg'), dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Classification Report (Hold-out)\n",
        "class_report = classification_report(y_val, y_pred, target_names=['Not Popular','Popular'])\n",
        "logger.info(\"\\nClassification Report (Hold-out):\\n%s\", class_report)\n",
        "\n",
        "# Precision-Recall Curve (Hold-out)\n",
        "prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_prob)\n",
        "pr_auc_val               = auc(rec_curve, prec_curve)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(rec_curve, prec_curve, label=f'PR AUC={pr_auc_val:.4f}', lw=2)\n",
        "plt.axhline(y=sum(y_val)/len(y_val), color='red', lw=1, linestyle='--',\n",
        "            label=f'Baseline={sum(y_val)/len(y_val):.3f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (Hold-out)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOT_DIR, 'pr_curve_holdout.jpg'), dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# ROC Curve (Hold-out)\n",
        "fpr, tpr, _ = roc_curve(y_val, y_prob)\n",
        "roc_auc_val = auc(fpr, tpr)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(fpr, tpr, label=f'ROC AUC={roc_auc_val:.4f}', lw=2)\n",
        "plt.plot([0,1],[0,1],'--', lw=1, color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Hold-out)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOT_DIR, 'roc_curve_holdout.jpg'), dpi=300)\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 7. 5-Fold Cross-Validation (Manual Loop)\n",
        "# ============================================================================\n",
        "logger.info(\"7) 5-Fold Cross-Validation 시작...\")\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=GLOBAL_SEED)\n",
        "\n",
        "acc_scores, f1_scores, roc_auc_scores = [], [], []\n",
        "precision_scores, recall_scores = [], []\n",
        "bal_acc_scores, logloss_scores = [], []\n",
        "mcc_scores = []\n",
        "topk_scores = []\n",
        "\n",
        "# best_iter가 0 이하일 때는 1로 보정\n",
        "n_iter = best_iter if (best_iter and best_iter > 0) else 1\n",
        "\n",
        "for fold_id, (train_idx, valid_idx) in enumerate(skf.split(X_tr, y_tr), start=1):\n",
        "    X_tr_fold, X_va_fold = X_tr.iloc[train_idx], X_tr.iloc[valid_idx]\n",
        "    y_tr_fold, y_va_fold = y_tr.iloc[train_idx], y_tr.iloc[valid_idx]\n",
        "\n",
        "    # Fold별 모델 생성 (same best_params + iterations)\n",
        "    fold_model = CatBoostClassifier(\n",
        "        iterations=n_iter,\n",
        "        task_type='GPU' if USE_GPU else 'CPU',\n",
        "        verbose=0,\n",
        "        random_state=GLOBAL_SEED,\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        **best_params\n",
        "    )\n",
        "\n",
        "    fold_model.fit(\n",
        "        X_tr_fold, y_tr_fold,\n",
        "        cat_features=cat_cols or None,\n",
        "        eval_set=[(X_va_fold, y_va_fold)],\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    y_va_prob = fold_model.predict_proba(X_va_fold)[:, 1]\n",
        "    y_va_pred = (y_va_prob >= 0.5).astype(int)\n",
        "\n",
        "    acc_f        = accuracy_score(y_va_fold, y_va_pred)\n",
        "    f1_f         = f1_score(y_va_fold, y_va_pred)\n",
        "    roc_auc_f    = roc_auc_score(y_va_fold, y_va_prob)\n",
        "    precision_f  = precision_score(y_va_fold, y_va_pred)\n",
        "    recall_f     = recall_score(y_va_fold, y_va_pred)\n",
        "    bal_acc_f    = balanced_accuracy_score(y_va_fold, y_va_pred)\n",
        "    logloss_f    = log_loss(y_va_fold, y_va_prob)\n",
        "    mcc_f        = matthews_corrcoef(y_va_fold, y_va_pred)\n",
        "\n",
        "    # Top-K Precision (상위 10% positive)\n",
        "    k_fold       = max(1, int(0.1 * sum(y_va_fold)))\n",
        "    topk_idx     = np.argsort(y_va_prob)[-k_fold:]\n",
        "    topk_prec_f  = sum(y_va_fold.iloc[topk_idx]) / k_fold\n",
        "\n",
        "    # 리스트에 저장\n",
        "    acc_scores.append(acc_f)\n",
        "    f1_scores.append(f1_f)\n",
        "    roc_auc_scores.append(roc_auc_f)\n",
        "    precision_scores.append(precision_f)\n",
        "    recall_scores.append(recall_f)\n",
        "    bal_acc_scores.append(bal_acc_f)\n",
        "    logloss_scores.append(logloss_f)\n",
        "    mcc_scores.append(mcc_f)\n",
        "    topk_scores.append(topk_prec_f)\n",
        "\n",
        "    # Fold별 로그 출력\n",
        "    logger.info(\n",
        "        \"Fold %d ➔ Acc=%.4f  F1=%.4f  ROC_AUC=%.4f  Prec=%.4f  Recall=%.4f  BalAcc=%.4f  MCC=%.4f  LogLoss=%.4f  Top-%d_Prec=%.4f\",\n",
        "        fold_id, acc_f, f1_f, roc_auc_f, precision_f, recall_f, bal_acc_f, mcc_f, logloss_f, k_fold, topk_prec_f\n",
        "    )\n",
        "\n",
        "# 평균 및 표준편차 계산 함수\n",
        "def mean_std(lst):\n",
        "    return np.mean(lst), np.std(lst)\n",
        "\n",
        "acc_mean,    acc_std    = mean_std(acc_scores)\n",
        "f1_mean,     f1_std     = mean_std(f1_scores)\n",
        "roc_mean,    roc_std    = mean_std(roc_auc_scores)\n",
        "prec_mean,   prec_std   = mean_std(precision_scores)\n",
        "rec_mean,    rec_std    = mean_std(recall_scores)\n",
        "bal_mean,    bal_std    = mean_std(bal_acc_scores)\n",
        "ll_mean,     ll_std     = mean_std(logloss_scores)\n",
        "mcc_mean,    mcc_std    = mean_std(mcc_scores)\n",
        "topk_mean,   topk_std   = mean_std(topk_scores)\n",
        "\n",
        "logger.info(\"\\n=== 5-Fold CV Results (Mean ± 2*STD) ===\")\n",
        "logger.info(\"Accuracy:          %.4f (+/- %.4f)\", acc_mean,    acc_std * 2)\n",
        "logger.info(\"F1 Score:          %.4f (+/- %.4f)\", f1_mean,     f1_std * 2)\n",
        "logger.info(\"ROC AUC:           %.4f (+/- %.4f)\", roc_mean,    roc_std * 2)\n",
        "logger.info(\"Precision:         %.4f (+/- %.4f)\", prec_mean,   prec_std * 2)\n",
        "logger.info(\"Recall:            %.4f (+/- %.4f)\", rec_mean,    rec_std * 2)\n",
        "logger.info(\"Balanced Accuracy: %.4f (+/- %.4f)\", bal_mean,    bal_std * 2)\n",
        "logger.info(\"Log Loss:          %.4f (+/- %.4f)\", ll_mean,     ll_std * 2)\n",
        "logger.info(\"MCC:               %.4f (+/- %.4f)\", mcc_mean,    mcc_std * 2)\n",
        "logger.info(\"Top-10%% Precision: %.4f (+/- %.4f)\", topk_mean,   topk_std * 2)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 8. Feature Importance & Permutation Importance\n",
        "# ============================================================================\n",
        "logger.info(\"8) Feature Importance 저장 중...\")\n",
        "# 내장된 Feature Importance (prettified=True)\n",
        "fi = final_model.get_feature_importance(prettified=True)\n",
        "fi.to_csv(FI_CSV, index=False)\n",
        "\n",
        "logger.info(\"   Permutation Importance 계산 중...\")\n",
        "def composite_scorer_func(y_true, y_pred_proba, **kw):\n",
        "    prob = y_pred_proba[:, 1] if y_pred_proba.ndim == 2 else y_pred_proba\n",
        "    pred = (prob >= 0.5).astype(int)\n",
        "    return (accuracy_score(y_true, pred)\n",
        "            + f1_score(y_true, pred)\n",
        "            + roc_auc_score(y_true, prob)) / 3\n",
        "\n",
        "custom_scorer = make_scorer(composite_scorer_func, needs_proba=True)\n",
        "\n",
        "pi = permutation_importance(\n",
        "    final_model, X_val, y_val,\n",
        "    scoring=custom_scorer,\n",
        "    n_repeats=5, random_state=GLOBAL_SEED, n_jobs=-1\n",
        ")\n",
        "pi_df = pd.DataFrame({\n",
        "    'feature'        : X_val.columns,\n",
        "    'importance_mean': pi.importances_mean,\n",
        "    'importance_std' : pi.importances_std\n",
        "})\n",
        "pi_df.to_csv(PI_CSV, index=False)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 9. SHAP Summary & Dependence Plot\n",
        "# ============================================================================\n",
        "logger.info(\"9) SHAP 계산 중 (시간 소요될 수 있음)...\")\n",
        "explainer = shap.TreeExplainer(final_model)\n",
        "shap_vals = explainer.shap_values(X_val, check_additivity=False)\n",
        "\n",
        "# SHAP Summary Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "shap.summary_plot(shap_vals, X_val, show=False)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOT_DIR, 'shap_summary.jpg'), dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# SHAP Dependence Plot: 'Feature Id' 컬럼에서 상위 N_DPND_FEATS개를 추출\n",
        "top_feats = fi.sort_values('Importances', ascending=False)['Feature Id'].head(N_DPND_FEATS)\n",
        "for feat in top_feats:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    shap.dependence_plot(feat, shap_vals, X_val,\n",
        "                         interaction_index='auto', show=False)\n",
        "    fn = f\"shap_dependence_{feat.replace('/','_')}.jpg\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(PLOT_DIR, fn), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 10. 로그 요약 및 완료\n",
        "# ============================================================================\n",
        "elapsed = time.time() - start_time if 'start_time' in globals() else 0\n",
        "h, m, s = int(elapsed // 3600), int((elapsed % 3600) // 60), int(elapsed % 60)\n",
        "logger.info(\"Total runtime: %dh %dm %ds\", h, m, s)\n",
        "logger.info(\"Artifacts saved to %s\", RES_DIR)"
      ]
    }
  ]
}